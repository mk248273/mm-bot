 What is AI observability and why does it matter? I get this question constantly and I thought I record this quick video to give you an overview of what I've learned over the last couple of months. Now, 84 percent of executives believe you need AI to grow the business and improve efficiency. I'm sure you've seen this yourself. I'm sure you've started to implement helping tools, self-service tools where your engineers can easier find information in your various knowledge databases. Think about a support engineer that gets a call and now with LLMs and with agents we can easily get the relevant information about that complaining customer to that engineer to become more efficient. We also see organizations that are building chat solutions in their websites. Classical example, Give me a recommendation on when I want to travel to my next destination. Give me a recommendation on hotels and on bookings. So these are some of these use cases that we see out there. Now, interesting fact is that only 33% of AI applications and AI projects are actually in production That rather low Also interesting is that one of the studies says that by 2027 by the end of 2027 40% of AI projects are getting canceled. So that's a lot of investment that never materializes to any business value. So these are some of the trends and I'm sure you've seen it. Think about it. What are the projects that you're currently doing to improve efficiency and to increase business output. Now I also want to talk a little bit about the challenges that I see. Why are projects failing? Why don't they deliver what we're hoping for? First is performance. We see a lot of problems with these systems not responding as fast as you would expect to actually get the gain out of it. So you need to have a way to measure performance and optimize it, optimize your model, optimizing your prompts. The next is around costs. This thing is not cheap, especially especially as you're connecting more and more systems. With agentic AI, we have now the ability to connect multiple systems to each other and then have agents capture information, produce a regular great output for us. And all of these interactions are just costly right So we also need to optimize these agents and these workflows Last thing is quality and compliance Not every answer is accurate I sure you have sometimes wondered what is this response to my prompt This doesn really make sense So we need to put in guardrails. We also need to think about compliance, because if you're using this technology and based on some of these answers to your prompts, you're giving advice, and this advice is wrong, well, you know, you are responsible for it. So this is some of the challenges and the trends. Now, where does AI observability come in? AI observability really needs a full stack approach from the top to the bottom. As you're building your apps, as you're integrating your models, as you're running it on different systems and different hardware, you need to have an end-to-end observability approach. There's going to be a lot of new components that we didn't have a couple of years a lot of great vendors and tools and frameworks. So you need to have an end to end approach to AI observability. From a Dynatrace perspective, we have a lot of different integrations with all of the major vendors out there, with all of the major frameworks. Also a quick shout out to Open LMTree. It a new standard where we can really trace your prompts through your systems to really understand what are the prompts that have been given what has actually happened and what came back Now we also have a lot of great examples on our Playground tenant whether this is automated, ready-made dashboards to monitor health and performance of your LLM systems, whether it's around guardrails, understanding how many of your prompts have actually been filtered out, do you have any toxicity, PRI leaks. These are all capabilities that your model providers will have, and then you need to measure, monitor, and act on it. Also compliance. I talked about compliance. Dynatrace provides an automated compliance and audit report where you can see which prompts have been executed by whom, and you can use this for compliance reasons. Also for optimization reasons. Talking about optimization, we give you an overview of the most expensive, the most executed prompts. This allows you to optimize your prompts. It allows you to optimize your agents. Also, what's an interesting fact is if you see that the same users are executing the same prompts all over again, let's say at eight o'clock in the morning for a stand up, they're asking your system for certain information. Well, maybe learn about this. And instead of them having to execute the prompt every day, maybe just send that information to them in a much more efficient way. With Dynatrace we give you a full end to end track

 because as you're building more complex AI and agentic systems, you need the end-to-end traceability to know which systems are involved in generating an answer to a prompt. Now, I mentioned we can explore all of this on the Dynatrace playground. And you know what? I just want to give you a quick tour on the playground so you can explore this yourself. So now let me walk over to my playground in a second. Here we go. That's the playground. That's the launchpad that we've prepared. Easy tips to get started. Also links to different apps. But if you really scroll down, we really break it down in individual sections. How can you measure the service health and performance, quality and guardrails? I think I showed some of this, the end-to-end traceability. Now, as you're getting closer to the bottom of the launchpad, you now get the links to the compliance report, the dashboards for OpenAI, for NVIDIA, for Kong, for Bedrock. So you have all of the different resources. Actually, let me just open up one of those. Let's start with this one. I have one single click and you get to all of these dashboards where we are showing you the key metrics around performance. Remember, performance, health, costs, guardrails. All of this is here in Dynatrace. Actionable. If you're using prompt caching, we are pulling in all of these details and giving you your cost analysis. So you can really figure out how costly are these prompts. And if you scroll down I a really big fan of performance optimization Here we give an overview of what are the top 10 most expensive prompts Also the slowest prompts Remember performance is something that your end users will perceive as is this a tool now where I can really become more efficient? If it's very slow, people will not see the value in it, right? So with all of these, right, we get an overview and then very simple with a click, you can say open record with and then for your developers that need to understand where did this prompt start and how did it kind of go through all of my system this is where you can get all of the information all right so also with with the prompts with the response everything is here cool let me go back to the the launchpad so the link to the launchpad you'll also find this in this video. Last maybe the compliance report. Compliance is a big, big topic. So make sure you're using also Dynatrace and AI observability to understand who is executing, what type of requests, what are the responses, what are the different models doing, what are certain trends, right? All of this here out of the box. All right. With this one, I want to leave you with AI is definitely upon us, right? You will create AI project, but we want to help you becoming more successful with your AI projects. If you start a project, we want to help you that it is cost efficient, that is performing, it produces the right quality, and you're also compliant. Okay, so keep these things in mind. Thank you so much. Bye-bye.

